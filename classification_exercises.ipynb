{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29427ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import env\n",
    "from env import user, password, host\n",
    "\n",
    "from pydataset import data\n",
    "import seaborn as sns\n",
    "\n",
    "#turn off pink warning boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import acquire file\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2dee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. In a jupyter notebook, classification_exercises.ipynb, use a python module (pydata or seaborn datasets)\n",
    "# containing datasets as a source from the iris data. Create a pandas dataframe, df_iris, from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8031066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = data('iris')\n",
    "df_iris.info()\n",
    "# data('iris', show_doc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f438ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 3 rows\n",
    "print(df_iris.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0022db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns (shape)\n",
    "print(df_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "print(df_iris.columns)\n",
    "o# or df_iris.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of each column\n",
    "print(df_iris.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2872f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary statistics for each of the numeric variables\n",
    "print(df_iris.describe().T) #.T transposes it for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88d32b",
   "metadata": {},
   "source": [
    "### # 5. Read the data from this google sheet into a dataframe, df_google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from this google sheet into a dataframe, df_google.\n",
    "\n",
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'    \n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_google = pd.read_csv(csv_export_url)\n",
    "df_google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d881e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the first 3 rows\n",
    "print(df_google.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef80ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns\n",
    "print(df_google.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2bc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "print(df_google.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1667d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of each column\n",
    "print(df_google.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37eb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary statistics for each of the numeric variables\n",
    "print(df_google.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5825e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique values for each of your categorical variables\n",
    "df_google.Survived.value_counts(dropna=False)\n",
    "df_google.Name.value_counts(dropna=False)\n",
    "df_google.Sex.value_counts(dropna=False)\n",
    "df_google.Cabin.value_counts(dropna=False)\n",
    "df_google.Embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304d9dd",
   "metadata": {},
   "source": [
    "### 6. Download the previous exercise's file into an excel (File → Download → Microsoft Excel). Read the downloaded file into a dataframe named df_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel(\"train.xlsx\", sheet_name='train')\n",
    "print(df_excel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ded79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the first 100 rows to a new dataframe, df_excel_sample\n",
    "df_excel_sample = df_excel.head(100)\n",
    "print(df_excel_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows of your original dataframe\n",
    "print(len(df_excel)) #or df_excel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb717e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 column names\n",
    "df_excel.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b41d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names that have a data type of object\n",
    "object_columns = df_excel.select_dtypes(include=['object']).head()\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08adfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the range for each of the numeric variables.\n",
    "titanic_stats = df_excel[['Age', 'Fare']].describe().T\n",
    "titanic_stats['range'] = titanic_stats['max'] -titanic_stats['min']\n",
    "titanic_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece855a",
   "metadata": {},
   "source": [
    "#### Make a new python module, acquire.py to hold the following data aquisition functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91746d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function named get_titanic_data that returns the titanic data from the codeup\n",
    "# data science database as a pandas data frame. Obtain your data from the Codeup Data Science Database.\n",
    "\n",
    "import env\n",
    "\n",
    "def get_titanic_data():\n",
    "    url = env.get_db_url('titanic_db')\n",
    "    \n",
    "    return pd.read_sql('SELECT * FROM passengers', url)\n",
    "\n",
    "get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813eca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function named get_iris_data that returns the data from the iris_db on the codeup\n",
    "# data science database as a pandas data frame. The returned data frame should include the \n",
    "# actual name of the species in addition to the species_ids. Obtain your data from the Codeup Data Science Database.\n",
    "from env import user, password, host\n",
    "\n",
    "#url = f'mysql+pymysql://{user}:{password}@{host}/iris_db'\n",
    "\n",
    "def get_iris_data():\n",
    "    from env import user, password, host\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/iris_db'\n",
    "    url = env.get_db_url('iris_db')\n",
    "    return pd.read_sql('SELECT * FROM measurements JOIN iris_db.species USING(species_id)', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb187ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e91caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function named get_telco_data that returns the data from the telco_churn database in SQL. \n",
    "# In your SQL, be sure to join contract_types, internet_service_types, payment_types tables with \n",
    "# the customers table, so that the resulting dataframe contains all the contract, payment, \n",
    "# and internet service options. Obtain your data from the Codeup Data Science Database.\n",
    "\n",
    "def get_telco_data():\n",
    "    from env import user, password, host\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/telco_churn'\n",
    "    url = env.get_db_url('telco_churn')\n",
    "    return pd.read_sql('SELECT * FROM customers\\\n",
    "    JOIN telco_churn.contract_types USING(contract_type_id)\\\n",
    "    JOIN telco_churn.internet_service_types USING(internet_service_type_id)\\\n",
    "    JOIN telco_churn.payment_types USING(payment_type_id)', url)\n",
    "\n",
    "get_telco_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969cab2",
   "metadata": {},
   "source": [
    "#### Once you've got your get_titanic_data, get_iris_data, and get_telco_data functions written, now it's time to add caching to them. To do this, edit the beginning of the function to check for the local filename of telco.csv, titanic.csv, or iris.csv. If they exist, use the .csv file. If the file doesn't exist, then produce the SQL and pandas necessary to create a dataframe, then write the dataframe to a .csv file with the appropriate name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d90c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_data():\n",
    "    filename = \"titanic.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        url = env.get_db_url('titanic_db')\n",
    "        return pd.read_sql('SELECT * FROM passengers', url)\n",
    "    \n",
    "titanic_df = get_titanic_data()\n",
    "titanic_df.to_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833962c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_data():\n",
    "    filename = \"iris.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        from env import user, password, host\n",
    "        url = f'mysql+pymysql://{user}:{password}@{host}/iris_db'\n",
    "        url = env.get_db_url('iris_db')\n",
    "        return pd.read_sql('SELECT * FROM measurements JOIN iris_db.species USING(species_id)', url)\n",
    "\n",
    "iris_df = get_iris_data()\n",
    "iris_df.to_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_telco_data():\n",
    "    filename = \"telco.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        from env import user, password, host\n",
    "        url = f'mysql+pymysql://{user}:{password}@{host}/telco_churn'\n",
    "        url = env.get_db_url('telco_churn')\n",
    "        return pd.read_sql('SELECT * FROM customers\\\n",
    "        JOIN telco_churn.contract_types USING(contract_type_id)\\\n",
    "        JOIN telco_churn.internet_service_types USING(internet_service_type_id)\\\n",
    "        JOIN telco_churn.payment_types USING(payment_type_id)', url)\n",
    "\n",
    "telco_df = get_telco_data()\n",
    "telco_df.to_csv(\"telco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e185b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use import acquire to get these functions from other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825e993",
   "metadata": {},
   "source": [
    "## Data Preparation Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa9224",
   "metadata": {},
   "source": [
    "The end product of this exercise should be the specified functions in a python script named prepare.py. Do these in your classification_exercises.ipynb first, then transfer to the prepare.py file.\n",
    "\n",
    "This work should all be saved in your local classification-exercises repo. Then add, commit, and push your changes.\n",
    "\n",
    "Using the Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use the function defined in acquire.py to load the iris data.\n",
    "iris_df = acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce314e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2501c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drop the species_id and measurement_id columns.\n",
    "iris_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['species_id', 'measurement_id']\n",
    "iris_df = iris_df.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45813e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Rename the species_name column to just species.\n",
    "iris_df = iris_df.rename(columns={'species_name': 'species'})\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f26238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create dummy variables of the species name and concatenate onto the iris dataframe. \n",
    "# (This is for practice, we don't always have to encode the target, but if we used species \n",
    "# as a feature, we would need to encode it).\n",
    "# Using drop_first leaves sex_male, embark_town_Queenstown, and embark_town_Southampton.\n",
    "\n",
    "dummy_df = pd.get_dummies(iris_df[['species']], dummy_na=False, drop_first=True)\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd177c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.concat([iris_df, dummy_df], axis=1)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2890bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Create a function named prep_iris that accepts the untransformed iris data, and returns the data\n",
    "# with the transformations above applied.\n",
    "def prep_iris(df):\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # Drop columns \n",
    "    columns_to_drop = ['species_id', 'measurement_id']\n",
    "    df = df.drop(columns = columns_to_drop)\n",
    "    # encoded categorical variables\n",
    "    dummy_df = pd.get_dummies(df[['species_name']], dummy_na=False, drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6212cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73053dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_iris_data()\n",
    "prep_iris(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936416c1",
   "metadata": {},
   "source": [
    "## Using the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a85ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Use the function defined in acquire.py to load the Titanic data.\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f42f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drop any unnecessary, unhelpful, or duplicated columns.\n",
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243238d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['embarked', 'pclass', 'passenger_id', 'deck']\n",
    "titanic_df = titanic_df.drop(columns = columns_to_drop) \n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical columns. Create dummy variables of the categorical columns and \n",
    "# concatenate them onto the dataframe.\n",
    "dummy_df = pd.get_dummies(titanic_df[['sex', 'class', 'embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate my dummy_df to my data\n",
    "\n",
    "titanic_df = pd.concat([titanic_df, dummy_df], axis=1)\n",
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a function named prep_titanic that accepts the raw titanic data, and returns the data\n",
    "# with the transformations above applied.\n",
    "def prep_titanic(df):\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # Drop columns \n",
    "    columns_to_drop = ['embarked', 'pclass', 'passenger_id', 'deck']\n",
    "    df = df.drop(columns = columns_to_drop)\n",
    "    # encoded categorical variables\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'class', 'embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7662d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "clean_titanic = prep_titanic(df)\n",
    "clean_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb6dfa8",
   "metadata": {},
   "source": [
    "## Using the Telco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f4d960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_type_id</th>\n",
       "      <th>internet_service_type_id</th>\n",
       "      <th>contract_type_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>...</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>churn</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>internet_service_type</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0002-ORFBO</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.3</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0003-MKNFE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.4</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0004-TLHLJ</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0011-IGKFF</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0013-EXCHZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   payment_type_id  internet_service_type_id  contract_type_id customer_id  \\\n",
       "0                2                         1                 2  0002-ORFBO   \n",
       "1                2                         1                 1  0003-MKNFE   \n",
       "2                1                         2                 1  0004-TLHLJ   \n",
       "3                1                         2                 1  0011-IGKFF   \n",
       "4                2                         2                 1  0013-EXCHZ   \n",
       "\n",
       "   gender  senior_citizen partner dependents  tenure phone_service  ...  \\\n",
       "0  Female               0     Yes        Yes       9           Yes  ...   \n",
       "1    Male               0      No         No       9           Yes  ...   \n",
       "2    Male               0      No         No       4           Yes  ...   \n",
       "3    Male               1     Yes         No      13           Yes  ...   \n",
       "4  Female               1     Yes         No       3           Yes  ...   \n",
       "\n",
       "  tech_support streaming_tv streaming_movies paperless_billing  \\\n",
       "0          Yes          Yes               No               Yes   \n",
       "1           No           No              Yes                No   \n",
       "2           No           No               No               Yes   \n",
       "3           No          Yes              Yes               Yes   \n",
       "4          Yes          Yes               No               Yes   \n",
       "\n",
       "  monthly_charges total_charges churn   contract_type  internet_service_type  \\\n",
       "0            65.6         593.3    No        One year                    DSL   \n",
       "1            59.9         542.4    No  Month-to-month                    DSL   \n",
       "2            73.9        280.85   Yes  Month-to-month            Fiber optic   \n",
       "3            98.0       1237.85   Yes  Month-to-month            Fiber optic   \n",
       "4            83.9         267.4   Yes  Month-to-month            Fiber optic   \n",
       "\n",
       "       payment_type  \n",
       "0      Mailed check  \n",
       "1      Mailed check  \n",
       "2  Electronic check  \n",
       "3  Electronic check  \n",
       "4      Mailed check  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Use the function defined in acquire.py to load the Telco data.\n",
    "telco_df = acquire.get_telco_data()\n",
    "telco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e2cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   payment_type_id           7043 non-null   int64  \n",
      " 1   internet_service_type_id  7043 non-null   int64  \n",
      " 2   contract_type_id          7043 non-null   int64  \n",
      " 3   customer_id               7043 non-null   object \n",
      " 4   gender                    7043 non-null   object \n",
      " 5   senior_citizen            7043 non-null   int64  \n",
      " 6   partner                   7043 non-null   object \n",
      " 7   dependents                7043 non-null   object \n",
      " 8   tenure                    7043 non-null   int64  \n",
      " 9   phone_service             7043 non-null   object \n",
      " 10  multiple_lines            7043 non-null   object \n",
      " 11  online_security           7043 non-null   object \n",
      " 12  online_backup             7043 non-null   object \n",
      " 13  device_protection         7043 non-null   object \n",
      " 14  tech_support              7043 non-null   object \n",
      " 15  streaming_tv              7043 non-null   object \n",
      " 16  streaming_movies          7043 non-null   object \n",
      " 17  paperless_billing         7043 non-null   object \n",
      " 18  monthly_charges           7043 non-null   float64\n",
      " 19  total_charges             7043 non-null   object \n",
      " 20  churn                     7043 non-null   object \n",
      " 21  contract_type             7043 non-null   object \n",
      " 22  internet_service_type     7043 non-null   object \n",
      " 23  payment_type              7043 non-null   object \n",
      "dtypes: float64(1), int64(5), object(18)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7043, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Drop any unnecessary, unhelpful, or duplicated columns. This could mean dropping foreign key columns\n",
    "# but keeping the corresponding string values, for example.\n",
    "telco_df.info()\n",
    "telco_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d18f32d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping duplicates, None here\n",
    "telco_df = telco_df.drop_duplicates()\n",
    "telco_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unneccessary columns\n",
    "columns_to_drop = ['payment_type_id', 'internet_service_type_id', 'contract_type_id']\n",
    "telco_df = telco_df.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1e43ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>...</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>churn</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>internet_service_type</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-ORFBO</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.3</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-MKNFE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.4</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-TLHLJ</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-IGKFF</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-EXCHZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Mailed check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  gender  senior_citizen partner dependents  tenure  \\\n",
       "0  0002-ORFBO  Female               0     Yes        Yes       9   \n",
       "1  0003-MKNFE    Male               0      No         No       9   \n",
       "2  0004-TLHLJ    Male               0      No         No       4   \n",
       "3  0011-IGKFF    Male               1     Yes         No      13   \n",
       "4  0013-EXCHZ  Female               1     Yes         No       3   \n",
       "\n",
       "  phone_service multiple_lines online_security online_backup  ...  \\\n",
       "0           Yes             No              No           Yes  ...   \n",
       "1           Yes            Yes              No            No  ...   \n",
       "2           Yes             No              No            No  ...   \n",
       "3           Yes             No              No           Yes  ...   \n",
       "4           Yes             No              No            No  ...   \n",
       "\n",
       "  tech_support streaming_tv streaming_movies paperless_billing  \\\n",
       "0          Yes          Yes               No               Yes   \n",
       "1           No           No              Yes                No   \n",
       "2           No           No               No               Yes   \n",
       "3           No          Yes              Yes               Yes   \n",
       "4          Yes          Yes               No               Yes   \n",
       "\n",
       "  monthly_charges  total_charges churn   contract_type internet_service_type  \\\n",
       "0            65.6          593.3    No        One year                   DSL   \n",
       "1            59.9          542.4    No  Month-to-month                   DSL   \n",
       "2            73.9         280.85   Yes  Month-to-month           Fiber optic   \n",
       "3            98.0        1237.85   Yes  Month-to-month           Fiber optic   \n",
       "4            83.9          267.4   Yes  Month-to-month           Fiber optic   \n",
       "\n",
       "       payment_type  \n",
       "0      Mailed check  \n",
       "1      Mailed check  \n",
       "2  Electronic check  \n",
       "3  Electronic check  \n",
       "4      Mailed check  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be657b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Encode the categorical columns. Create dummy variables of the categorical columns and concatenate\n",
    "# them onto the dataframe.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
