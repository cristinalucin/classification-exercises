{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a304ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. In a jupyter notebook, classification_exercises.ipynb, use a python module (pydata or seaborn datasets)\n",
    "# containing datasets as a source from the iris data. Create a pandas dataframe, df_iris, from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7632c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = data('iris')\n",
    "df_iris.info()\n",
    "# data('iris', show_doc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ba2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 3 rows\n",
    "print(df_iris.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns (shape)\n",
    "print(df_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "print(df_iris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00be387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of each column\n",
    "print(df_iris.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary statistics for each of the numeric variables\n",
    "print(df_iris.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would you recommend rescaling the data based on these statistics?\n",
    "##\n",
    "data('iris', show_doc=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9618bd9",
   "metadata": {},
   "source": [
    "### # 5. Read the data from this google sheet into a dataframe, df_google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed115cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from this google sheet into a dataframe, df_google.\n",
    "\n",
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'    \n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_google = pd.read_csv(csv_export_url)\n",
    "df_google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the first 3 rows\n",
    "print(df_google.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns\n",
    "print(df_google.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "print(df_google.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac354580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of each column\n",
    "print(df_google.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ae4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary statistics for each of the numeric variables\n",
    "print(df_google.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db186073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique values for each of your categorical variables\n",
    "print(df_google.Survived.unique, df_google.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f33cc0",
   "metadata": {},
   "source": [
    "### 6. Download the previous exercise's file into an excel (File → Download → Microsoft Excel). Read the downloaded file into a dataframe named df_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel(\"train.xlsx\")\n",
    "print(df_excel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the first 100 rows to a new dataframe, df_excel_sample\n",
    "df_excel_sample = df_excel.head(100)\n",
    "print(df_excel_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows of your original dataframe\n",
    "print(len(df_excel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 column names\n",
    "df_excel.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names that have a data type of object\n",
    "object_columns = df_excel.select_dtypes(include=['object']).columns\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11da9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the range for each of the numeric variables.\n",
    "float_columns = df_excel.select_dtypes(include=['float64']).columns\n",
    "range(float_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3fff6f",
   "metadata": {},
   "source": [
    "#### Make a new python module, acquire.py to hold the following data aquisition functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function named get_titanic_data that returns the titanic data from the codeup\n",
    "# data science database as a pandas data frame. Obtain your data from the Codeup Data Science Database.\n",
    "\n",
    "import env\n",
    "\n",
    "def get_titanic_data():\n",
    "    url = env.get_db_url('titanic_db')\n",
    "    \n",
    "    return pd.read_sql('SELECT * FROM passengers', url)\n",
    "\n",
    "get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eee475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function named get_iris_data that returns the data from the iris_db on the codeup\n",
    "# data science database as a pandas data frame. The returned data frame should include the \n",
    "# actual name of the species in addition to the species_ids. Obtain your data from the Codeup Data Science Database.\n",
    "from env import user, password, host\n",
    "\n",
    "#url = f'mysql+pymysql://{user}:{password}@{host}/iris_db'\n",
    "\n",
    "def get_iris_data():\n",
    "    from env import user, password, host\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/iris_db'\n",
    "    url = env.get_db_url('iris_db')\n",
    "    return pd.read_sql('SELECT * FROM measurements JOIN iris_db.species USING(species_id)', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c936f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function named get_telco_data that returns the data from the telco_churn database in SQL. \n",
    "# In your SQL, be sure to join contract_types, internet_service_types, payment_types tables with \n",
    "# the customers table, so that the resulting dataframe contains all the contract, payment, \n",
    "# and internet service options. Obtain your data from the Codeup Data Science Database.\n",
    "\n",
    "def get_telco_data():\n",
    "    from env import user, password, host\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/telco_churn'\n",
    "    url = env.get_db_url('telco_churn')\n",
    "    return pd.read_sql('SELECT * FROM customers\\\n",
    "    JOIN telco_churn.contract_types USING(contract_type_id)\\\n",
    "    JOIN telco_churn.internet_service_types USING(internet_service_type_id)\\\n",
    "    JOIN telco_churn.payment_types USING(payment_type_id)', url)\n",
    "\n",
    "get_telco_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e786b2b",
   "metadata": {},
   "source": [
    "#### Once you've got your get_titanic_data, get_iris_data, and get_telco_data functions written, now it's time to add caching to them. To do this, edit the beginning of the function to check for the local filename of telco.csv, titanic.csv, or iris.csv. If they exist, use the .csv file. If the file doesn't exist, then produce the SQL and pandas necessary to create a dataframe, then write the dataframe to a .csv file with the appropriate name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_data():\n",
    "    filename = \"titanic.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        url = env.get_db_url('titanic_db')\n",
    "        return pd.read_sql('SELECT * FROM passengers', url)\n",
    "    \n",
    "titanic_df = get_titanic_data()\n",
    "titanic_df.to_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ce522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_data():\n",
    "    filename = \"iris.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        from env import user, password, host\n",
    "        url = f'mysql+pymysql://{user}:{password}@{host}/iris_db'\n",
    "        url = env.get_db_url('iris_db')\n",
    "        return pd.read_sql('SELECT * FROM measurements JOIN iris_db.species USING(species_id)', url)\n",
    "\n",
    "iris_df = get_iris_data()\n",
    "iris_df.to_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30293ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_telco_data():\n",
    "    filename = \"telco.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        from env import user, password, host\n",
    "        url = f'mysql+pymysql://{user}:{password}@{host}/telco_churn'\n",
    "        url = env.get_db_url('telco_churn')\n",
    "        return pd.read_sql('SELECT * FROM customers\\\n",
    "        JOIN telco_churn.contract_types USING(contract_type_id)\\\n",
    "        JOIN telco_churn.internet_service_types USING(internet_service_type_id)\\\n",
    "        JOIN telco_churn.payment_types USING(payment_type_id)', url)\n",
    "\n",
    "telco_df = get_telco_data()\n",
    "telco_df.to_csv(\"telco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9219c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
