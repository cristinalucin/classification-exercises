{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f732cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General DS Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1e9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree and Model Evaluation Imports\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2bd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my acquire and prepare file\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from prepare import train_validate_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f6a81",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02af63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquire\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ea630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare titanic data\n",
    "titanic_df = prepare.prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "titanic_df.drop(['embark_town'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48058853",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db43cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train validate test split\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa29473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic_df, target='survived', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83228d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features.\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate and Test \n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dc370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Baseline\n",
    "y_train.value_counts()\n",
    "#Baseline is 0, did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish Baseline\n",
    "y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc27eb",
   "metadata": {},
   "source": [
    "####  baseline prediction? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d59ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Accuracy\n",
    "(y_train == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15e1db",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d51f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360009ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(tree, feature_names=X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree NOT WORKING\n",
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree, feature_names=X_train.columns, class_names=y_train.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your model to make predictions on the in-sample data\n",
    "tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e411eaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m      2\u001b[0m actual \u001b[38;5;241m=\u001b[39m y_train\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "y_predictions = tree.predict(X_train)\n",
    "actual = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d989adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline accuracy\n",
    "(y_train == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781bea8",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0afcf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904fbbb8",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38030735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On validate data\n",
    "predictions = tree.predict(X_validate)\n",
    "actual = y_validate\n",
    "\n",
    "print(classification_report(actual, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61592fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70af76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "      .format(tree.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c960992",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tree.score(X_train, y_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f18e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Could calculate this way, need to define y predictions\n",
    "#TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()\n",
    "#TP, FP, FN, TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2060a5",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde0694",
   "metadata": {},
   "source": [
    "#### Using Tree 2, 4 levels of depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af48ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "tree2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(tree, feature_names=X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your model to make predictions on the in-sample data\n",
    "tree2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree2.predict(X_train)\n",
    "actual = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca79b18",
   "metadata": {},
   "source": [
    "#### Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb642327",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3098d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1dbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating from validation data\n",
    "predictions = tree2.predict(X_validate)\n",
    "actual = y_validate\n",
    "\n",
    "print(classification_report(actual, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "      .format(tree2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea1cab",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree2 (model 2) performs better on my sample (training) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a76a3",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd28ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree 1 (model 1) performs better on the validate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5376e64",
   "metadata": {},
   "source": [
    "## CONCLUSIONS: By changing max depth to four levels, we increased accuracy slightly, but also made a more precise model (model 2 aka 'Tree 2' had a much lower false positive rate than model 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71006917",
   "metadata": {},
   "source": [
    "--------------------###------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b0366",
   "metadata": {},
   "source": [
    "## TELCO DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquire\n",
    "df = acquire.get_telco_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep telco data\n",
    "def prep_telco_data(df):\n",
    "    # Drop duplicate columns\n",
    "    df.drop(columns=['payment_type_id', 'internet_service_type_id', 'contract_type_id', 'customer_id'], inplace=True)\n",
    "       \n",
    "    # Drop null values stored as whitespace    \n",
    "    df['total_charges'] = df['total_charges'].str.strip()\n",
    "    df = df[df.total_charges != '']\n",
    "    \n",
    "    # Convert to correct datatype\n",
    "    df['total_charges'] = df.total_charges.astype(float)\n",
    "    \n",
    "    # Convert binary categorical variables to numeric\n",
    "    df['gender_encoded'] = df.gender.map({'Female': 1, 'Male': 0})\n",
    "    df['partner_encoded'] = df.partner.map({'Yes': 1, 'No': 0})\n",
    "    df['dependents_encoded'] = df.dependents.map({'Yes': 1, 'No': 0})\n",
    "    df['phone_service_encoded'] = df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    df['paperless_billing_encoded'] = df.paperless_billing.map({'Yes': 1, 'No': 0})\n",
    "    df['churn_encoded'] = df.churn.map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # Get dummies for non-binary categorical variables\n",
    "    dummy_df = pd.get_dummies(df[['multiple_lines', \\\n",
    "                              'online_security', \\\n",
    "                              'online_backup', \\\n",
    "                              'device_protection', \\\n",
    "                              'tech_support', \\\n",
    "                              'streaming_tv', \\\n",
    "                              'streaming_movies', \\\n",
    "                              'contract_type', \\\n",
    "                              'internet_service_type', \\\n",
    "                              'payment_type']], dummy_na=False, \\\n",
    "                              drop_first=True)\n",
    "    \n",
    "    # Concatenate dummy dataframe to original \n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb89e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_telco_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "df.drop(['gender','partner','dependents','phone_service','multiple_lines',\\\n",
    "                              'online_security', \\\n",
    "                              'online_backup', \\\n",
    "                              'device_protection', \\\n",
    "                              'tech_support', \\\n",
    "                              'streaming_tv', \\\n",
    "                              'streaming_movies', \\\n",
    "                              'contract_type', \\\n",
    "                              'internet_service_type', \\\n",
    "                              'payment_type', \\\n",
    "                              'paperless_billing', \\\n",
    "                              'churn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74780f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming churn encoded\n",
    "df.rename(columns = {'churn_encoded':'churn'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346b326",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='churn', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d31fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features.\n",
    "X_train = train.drop(columns=['churn'])\n",
    "y_train = train.churn\n",
    "train.churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcef906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape\n",
    "train.shape\n",
    "validate.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9651c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create validate and test data\n",
    "#Validate and Test \n",
    "X_validate = validate.drop(columns=['churn'])\n",
    "y_validate = validate.churn\n",
    "\n",
    "X_test = test.drop(columns=['churn'])\n",
    "y_test = test.churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Baseline\n",
    "y_train.value_counts()\n",
    "#Baseline is 0, customer did not churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Accuracy\n",
    "(y_train == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244c092",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b34954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d761a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "tree1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(tree1, feature_names=X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bdce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your model to make predictions on the in-sample data\n",
    "tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398ef81",
   "metadata": {},
   "source": [
    "--------------------##Random Forest Exercises##--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e619532",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquire\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare titanic data\n",
    "titanic_df = prepare.prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80057edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "titanic_df.drop(['embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad400172",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import train_validate_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic_df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66297460",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(X_train.columns, rf.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f53f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa207b5",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mode for target?\n",
    "y_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish our baseline prediction \n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Next let establish a baseline accuracy\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline prediction: {baseline[0]}\")\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model's performance on train\n",
    "y_predictions = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab51b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of depth 10\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74301991",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9572e79",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb25acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn confusion matrix\n",
    "cm = confusion_matrix(y_train, y_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18483cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classification report on training data\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9bea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1379c",
   "metadata": {},
   "source": [
    "### Looking at performance on validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ed9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6353594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of validate set\n",
    "print('Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = rf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classification report on validate data\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_validate,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9d01c",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df448ed",
   "metadata": {},
   "source": [
    "### Model 2: min_samples_leaf = 3 and max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquire\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f32c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare titanic data\n",
    "titanic_df = prepare.prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "titanic_df.drop(['embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de06a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic_df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increasing min samples leaf and decreasing max depth\n",
    "rf2 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55148e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print feature importances\n",
    "print(rf2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show feature importances\n",
    "plt.bar(X_train.columns, rf2.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945deae0",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66823214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = rf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4391df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf2.predict_proba(X_train)\n",
    "y_pred_proba\n",
    "#Tells the prediction of probability a being made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd8a9f",
   "metadata": {},
   "source": [
    "#### Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mode for target\n",
    "y_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish our baseline prediction \n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Next let establish a baseline accuracy\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline prediction: {baseline[0]}\")\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ea968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model's performance on train\n",
    "y_predictions = rf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9145c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier model 2 on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bef5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of depth 5\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb7f3d",
   "metadata": {},
   "source": [
    "#### Calculate accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn confusion matrix\n",
    "cm = confusion_matrix(y_train, y_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf2.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classification report on training data\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a22313",
   "metadata": {},
   "source": [
    "### Looking at performance on validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235bdc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of validate set\n",
    "print('Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = rf2.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0be123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classification report on validate data\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_validate,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699e5b3",
   "metadata": {},
   "source": [
    "### Model 3: min_leaf_samples = 3 and max_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquire\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f14910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare titanic data\n",
    "titanic_df = prepare.prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "titanic_df.drop(['embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6035009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic_df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min samples leaf = 3 and max depth of 10\n",
    "rf3 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ddef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf3.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324bef7",
   "metadata": {},
   "source": [
    "#### Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c713aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mode for target\n",
    "y_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model's performance on train\n",
    "y_predictions = rf3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier model 3 on training set: {:.2f}'\n",
    "     .format(rf3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa22eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of depth 10\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn confusion matrix\n",
    "cm = confusion_matrix(y_train, y_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf3.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09056429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classification report on training data\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d0d41",
   "metadata": {},
   "source": [
    "### Looking at performance on validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53471b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of validate set\n",
    "print('Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "y_pred = rf3.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classification report on validate data\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_validate,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3477f6",
   "metadata": {},
   "source": [
    "### CONCLUSION:\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4be56",
   "metadata": {},
   "source": [
    "-------## KNN Problems ##-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1e29f",
   "metadata": {},
   "source": [
    "## 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dfe90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquire\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d95866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare titanic data\n",
    "titanic_df = prepare.prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ebd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not needed for modeling\n",
    "titanic_df.drop(['embark_town'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b516403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic_df, target='survived', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a76f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute age\n",
    "train, validate, test = prepare.impute_mean_age(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d211f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape\n",
    "#X_validate.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb03a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a19072",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccef591",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba43056",
   "metadata": {},
   "source": [
    "### 2. evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f12d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29970770",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fae1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd4d7b",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b39e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5948ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544918a5",
   "metadata": {},
   "source": [
    "### Performance on Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c013df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN (k=5) classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16436315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish predictions from validate data\n",
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ef8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19837e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_validate, y_pred).ravel()\n",
    "\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6d648",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89744df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2833a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a24f83",
   "metadata": {},
   "source": [
    "#### evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e59272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ebc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147963d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae60c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2ebd3",
   "metadata": {},
   "source": [
    "### Performance on Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba420d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN (k=10) classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish predictions from validate data\n",
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12313110",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_validate, y_pred).ravel()\n",
    "\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7fe6c",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d76a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54657905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1369297",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95907e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b025ec1",
   "metadata": {},
   "source": [
    "### Performance on Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN (k=20) classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish predictions from validate data\n",
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634306ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_validate, y_pred).ravel()\n",
    "\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c6197",
   "metadata": {},
   "source": [
    "### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac36ad",
   "metadata": {},
   "source": [
    "### For in-sample Data\n",
    "#### Model 1 (k =5)\n",
    "\n",
    "#### Model 2 (k=10)\n",
    "\n",
    "#### Model 3 (k=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68808a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The first model appears to perform better on in-sample data in some key measures (accuracy 76%), and leads\n",
    "### the three models in Recall (65%). Model 2 has slightly better precision but lower accuracy and a lower recall (51%).\n",
    "### The last model performs almost last in all metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14960add",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first model performs best on out of sample data (accuracy 76 percent). The third model performs\n",
    "# slightly better on out of sample data (validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03787510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Baseline\n",
    "y_train.value_counts()\n",
    "#Baseline is 0, did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Accuracy\n",
    "(y_train == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe4129",
   "metadata": {},
   "source": [
    "### -------------------LOGISTIC REGRESSION----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b798e",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8cc94169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_Cherbourg</th>\n",
       "      <th>embark_Queenstown</th>\n",
       "      <th>embark_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  embark_town  alone  \\\n",
       "0         0       3  22.0      1      0   7.2500  Southampton      0   \n",
       "1         1       1  38.0      1      0  71.2833    Cherbourg      0   \n",
       "2         1       3  26.0      0      0   7.9250  Southampton      1   \n",
       "3         1       1  35.0      1      0  53.1000  Southampton      0   \n",
       "4         0       3  35.0      0      0   8.0500  Southampton      1   \n",
       "\n",
       "   is_female  embark_Cherbourg  embark_Queenstown  embark_Southampton  \n",
       "0          0                 0                  0                   1  \n",
       "1          1                 1                  0                   0  \n",
       "2          1                 0                  0                   1  \n",
       "3          1                 0                  0                   1  \n",
       "4          0                 0                  0                   1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Acquire\n",
    "titanic_df = acquire.get_titanic_data()\n",
    "### Prepare\n",
    "titanic_df = prepare.prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3c1ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping embark_town\n",
    "titanic_df.drop(['embark_town'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c029dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test_split(titanic_df, target='survived', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5171eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute age\n",
    "train, validate, test = prepare.impute_mean_age(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b433e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d44a1d",
   "metadata": {},
   "source": [
    "### 1. Create a model that includes age in addition to fare and pclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04e3ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       384\n",
      "           1       0.66      0.42      0.51       239\n",
      "\n",
      "    accuracy                           0.70       623\n",
      "   macro avg       0.68      0.64      0.65       623\n",
      "weighted avg       0.69      0.70      0.68       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit1 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify features\n",
    "features1 = ['age', 'fare', 'pclass']\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit1.fit(X_train[features1], y_train)\n",
    "\n",
    "y_pred1 = logit1.predict(X_train[features1])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features1], y_train)))\n",
    "\n",
    "# classification report for Model 2 using train data\n",
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62e9b458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.04012056  0.00639302 -0.9277399 ]]\n",
      "Intercept: \n",
      " [2.64369846]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit1.coef_)\n",
    "print('Intercept: \\n', logit1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "812aa12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit1.predict_proba(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a702fd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6826964 , 0.3173036 ],\n",
       "       [0.52545906, 0.47454094],\n",
       "       [0.72297807, 0.27702193],\n",
       "       ...,\n",
       "       [0.6294886 , 0.3705114 ],\n",
       "       [0.76367561, 0.23632439],\n",
       "       [0.57143343, 0.42856657]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fb83362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  51]\n",
      " [139 100]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d699f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       384\n",
      "           1       0.66      0.42      0.51       239\n",
      "\n",
      "    accuracy                           0.70       623\n",
      "   macro avg       0.68      0.64      0.65       623\n",
      "weighted avg       0.69      0.70      0.68       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddfc669",
   "metadata": {},
   "source": [
    "### Performance on Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca5b2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = logit1.predict(X_validate[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a77a52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 performance on validate\n",
      "Accuracy: 0.69\n",
      "[[67 15]\n",
      " [27 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76        82\n",
      "           1       0.62      0.48      0.54        52\n",
      "\n",
      "    accuracy                           0.69       134\n",
      "   macro avg       0.67      0.65      0.65       134\n",
      "weighted avg       0.68      0.69      0.68       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1 performance on validate\")\n",
    "\n",
    "# accuracy of model 1\n",
    "print('Accuracy: {:.2f}'.format(logit1.score(X_validate[features], y_validate)))\n",
    "\n",
    "# confusion matrix of model 1\n",
    "print(confusion_matrix(y_validate, y_pred1))\n",
    "\n",
    "# classification report of model 1\n",
    "print(classification_report(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01591378",
   "metadata": {},
   "source": [
    "### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "664ab309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6163723916532905"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n",
    "#Baseline is 0, did not survive\n",
    "#Baseline Accuracy\n",
    "(y_train == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808afd2",
   "metadata": {},
   "source": [
    "### 1. Does this model perform better than your baseline? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yes it does (0.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948681e",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4256bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify features\n",
    "features2 = ['age', 'fare', 'pclass', 'is_female']\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit2.fit(X_train[features2], y_train)\n",
    "\n",
    "y_pred = logit2.predict(X_train[features2])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train[features2], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa6a432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03815414  0.00292526 -1.10149471  2.41405025]]\n",
      "Intercept: \n",
      " [2.13283132]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit2.coef_)\n",
    "print('Intercept: \\n', logit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c877a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323  61]\n",
      " [ 68 171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       384\n",
      "           1       0.74      0.72      0.73       239\n",
      "\n",
      "    accuracy                           0.79       623\n",
      "   macro avg       0.78      0.78      0.78       623\n",
      "weighted avg       0.79      0.79      0.79       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e375a7",
   "metadata": {},
   "source": [
    "### Performance on Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e95db30b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but LogisticRegression is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred2 \u001b[38;5;241m=\u001b[39m \u001b[43mlogit2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_validate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but LogisticRegression is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "y_pred2 = logit2.predict(X_validate[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69978113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 performance on validate\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but LogisticRegression is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel 2 performance on validate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# accuracy of model 2\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mlogit2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_validate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validate\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# confusion matrix of model 2\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_validate, y_pred))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:651\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but LogisticRegression is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "print(\"Model 2 performance on validate\")\n",
    "\n",
    "# accuracy of model 2\n",
    "print('Accuracy: {:.2f}'.format(logit2.score(X_validate[features], y_validate)))\n",
    "\n",
    "# confusion matrix of model 2\n",
    "print(confusion_matrix(y_validate, y_pred))\n",
    "\n",
    "# classification report of model 2\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669fcf0",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b38ae6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit3 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify features\n",
    "features = ['age', 'fare', 'pclass']\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit3.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit3.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit3.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22b7e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.04012056  0.00639302 -0.9277399 ]]\n",
      "Intercept: \n",
      " [2.64369846]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4090b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  51]\n",
      " [139 100]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4829c8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       384\n",
      "           1       0.66      0.42      0.51       239\n",
      "\n",
      "    accuracy                           0.70       623\n",
      "   macro avg       0.68      0.64      0.65       623\n",
      "weighted avg       0.69      0.70      0.68       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf8ef0",
   "metadata": {},
   "source": [
    "### Performance on Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4d08c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = logit3.predict_proba(X_validate[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebdd7779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85e3cb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 performance on validate\n",
      "Accuracy: 0.69\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(logit3\u001b[38;5;241m.\u001b[39mscore(X_validate[features], y_validate)))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# confusion matrix of model 3\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_validate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred3\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# classification report of model 3\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_validate, y_pred3))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[1;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m ):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "print(\"Model 3 performance on validate\")\n",
    "\n",
    "# accuracy of model 3\n",
    "print('Accuracy: {:.2f}'.format(logit3.score(X_validate[features], y_validate)))\n",
    "\n",
    "# confusion matrix of model 3\n",
    "print(confusion_matrix(y_validate, y_pred3))\n",
    "\n",
    "# classification report of model 3\n",
    "print(classification_report(y_validate, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c880f",
   "metadata": {},
   "source": [
    "### Using Pclass, alone, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eec2711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify features\n",
    "features = ['pclass', 'alone', 'is_female']\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit4.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8002d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.9164229  -0.34778639  2.36609031]]\n",
      "Intercept: \n",
      " [0.90697958]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit4.coef_)\n",
    "print('Intercept: \\n', logit4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2429b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = logit4.predict_proba(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f02b0b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d29c7b80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred4\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[1;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m ):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35906353",
   "metadata": {},
   "source": [
    "### Using Pclass, sex, embark Cherbourg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7eebf1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit5 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify features\n",
    "features = ['pclass', 'is_female', 'embark_Cherbourg']\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit5.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit5.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit5.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db4dfe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred_proba = logit5.predict_proba(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147afa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745b3f5",
   "metadata": {},
   "source": [
    "### 4. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pclass, sex, embark Cherbourg gave the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on train data\n",
    "\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "# accuracy of model 1\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_train, y_train)))\n",
    "\n",
    "# confusion matrix of model 1\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "# classification report of model 1\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1beafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on test\n",
    "\n",
    "y_pred = logit.predict(X_test)\n",
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "# accuracy of model 4\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_test, y_test)))\n",
    "# confusion matrix of model 4\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# classification report of model 4\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba63b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
